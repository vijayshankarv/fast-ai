{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 3 - CNNs\n",
    "\n",
    "https://www.youtube.com/watch?v=6kwQEBMandw&feature=youtu.be&t=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with random filters (or weights for the filter matrices) and then use SGD to optimize these weights - How does one choose the size and how do you update them? \n",
    "\n",
    "How does a convolution differ from a fully connected layer? Jeremy says it is a subset of the fully connected layer\n",
    "\n",
    "Are the filters the layers? Look at simple little convolutions \n",
    "\n",
    "\n",
    "You can create as many filters as you want - an\n",
    "\n",
    "In vgg, the number of layers keep increasing. Why are they increasing? You are doing max pooling and looking at larger number of smaller images? (This is where the renormalization group analogy from physics comes in)  \n",
    "\n",
    "Why can't the imagenet model be finetuned on cartoons? Neural network is tuned for nuances in real world photographs and this may not apply to cartoon images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax \n",
    "\n",
    "$\\frac{\\exp(x[i])}{\\sum(\\exp(x))}$\n",
    "\n",
    "\n",
    "Good for getting probablities from an output set of weights\n",
    "See example below - this is kind of like a partition function for energies without the minus sign\n",
    "\n",
    "Also good for one hot encoding which is what we need from the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([4.51, -2.11, 0.57, -4.06, -3.85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_x = np.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "softmax_x = exp_x/np.sum(exp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3,suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.979,  0.001,  0.019,  0.   ,  0.   ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State farm dataset for distracted driving\n",
    "\n",
    "Only retrain the fully connected layers from imageset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the first few layers (convolutional layers) and then remove dropout from the fully connected layer so that we are overfitting - (training error less than validation error) \n",
    "\n",
    "If you are overfitting, then you need to add dropout. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation - creating new pieces of data by adding rotations, distortions etc\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
